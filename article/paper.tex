\section{Introduction}
The best paper in the world is~\cite{Liben-Nowell:2003:LPP:956863.956972}.

\input link-prediction

\section{Implementation}
The selected algorithms were implemented and tested over three different 
database systems: Relational, Key-Value store and Graph. 
In each system we attempted to implement the algorithms as natively as possible, 
using that system's features and applying common optimizations. 

For the bechmarking we chose MySQL, Redis and Neo4J.
These databases are all open-source, enabling us to publish these benchmarks,
and popular in their domain, therefore considered as a viable option for such social network implementation.

\subsection{MySQL}
MySQL is a popular multi-platform, open-source relational database management
system, sponsored by Oracle. It can be used in client-server or embedded
architecture and it's main features include: 
\begin{itemize}
	\item {\bf Pluggable storage-engines:} MySQL supports several storage engines, 
		most notables are MyISM (fast, simple, no ACID support, no foreign keys) and
		InnoDB (default, supports transactions, ACID and foreign keys).
	\item {\bf Stored Procedures} Like most other relational databases MySQL supports 
		stored procedures execution. Advantages of this feature include 
		avoidance of network traffic for the SQL queries and intermediate results,
		and encapsulation of a multi-query logic in one place.
	\item {\bf Fast Bulk Data Loading} MySQL support very fast data loading from file,
		with it's 'LOAD DATA' statement. From all the systems we tested, this offered 
		the easiest and fastest way to load our graph.
\end{itemize}

In this case, the algorithms were implemented as a SQL stored-procedures,
using indices and intermediate tables when possible. A Python script was used
to run these stored-procedures and collect the benchmarks. For a storage-engine 
we chose InnoDB, the default engine in MySQL 5.5, as it out-performs MyISM in 
most senarios. \footnote{Sara: can we cite Oracle white papers? 
http://www.oracle.com/partners/en/knowledge-zone/mysql-5-5-innodb-myisam-522945.pdf}
\linebreak

Implementation details:
\begin{itemize}
	\item {\bf Helper Tables} 
        We generated the following helper tables to speed up some algorithms:
		\begin{itemize}
			\item {common-neighbors (id1, id2, neighbor)}
			\item {common-neighbors-count (id1, id2, number of common neighbors)}
			\item {neighbors (id, number of neighbors)}
			\item {topN (id, number of neighbors)}
				This table is simply the top 101 items of the neighbors table.
		\end{itemize}
	\item {\bf Common Neighbors (global)} 
		To find the top N records with most common neighbors, 
		we selected them from the common-neighbors-count table.
	\item {\bf Jaccard's Coefficient (global)} 
		We used the following relation between the cardinality of union and intersection:
		\[{|N(x) \cup N(y)|} = {|N(x)| + |N(y)| - |N(x) \cap N(y)|}\]
		So to calculate the score we used the common-neighbors-count and the neighbors helper tables.
	\item {\bf Adamic/Adar (global)} 
		We used the common-neighbors joined with the neighbors helper table.
	\item {\bf Preferential attachment (Global)}
		We used only the topN helper table, because the highest products 
		must be combinations of the nodes with most neighbors.
	\item {\bf Common Neighbors (for node)}
		We used a simple join on the edges table, no helper tables required.
	\item {\bf Jaccard's Coefficient (for node)}
		We used the relation between the cardinality of union and intersection,
		with join of two edges tables, and two neighbors helper tables.
	\item {\bf Adamic/Adar (for node)}
		We used join on the edges table, with the neighbors helper table.
	\item {\bf Preferential attachment (for node)}
		We used the topN helper table, just like in the global version.
	\item {\bf Graph Distance (for node)}
		We used a recursive procedure, starting with a temporary table with all the node's neighbors,
		and on each iteration N we added all the neighbors of nodes in depth N-1. This implementation
		required us to reconfigure MySQL maximum recursion depth.
	\item {\bf Katz (for node)}
		We used a recursive procedure to calculate $|P^l(x,y)|$ for all reachable nodes in depth 3,
		and stored that in a temporary table. We then used that to calculate the score.
	\item {\bf Rooted PageRank (for node)}
        We used an iterative loop over a temporary table <id, rpr, new-rpr>, initiated with all the 
        nodes in the graph, and 1/N value where N is the number of nodes in the graph. On every 
        iteration we updated the new-rpr value, using the formula above. We stopped when the algorithm
        converged on the top-10 scoring nodes and their order.
\end{itemize}

\subsection{Redis}
Redis is an open-source, in-memory key-value store database system, sponsored
by VMware. It's written in C and has atomic operations, we used the following features:
\begin{itemize}
	\item {\bf Transactions}
        You can use redis transaction to save time spent on network trafic 
        between the client API and the server. We used that feature to speed up
        the graph load significantly.
	\item {\bf Data structure as value}
        Redis support storing many types of data structures as valuse and 
        performe efficient, atomic operation over them. I.e. there are strings,
        hashes (key-value pairs), lists, sets (in which we used to store the 
        adjacency lists), and sorted-sets (like sets, but with rank for each item).
        Operations include: incrementing value in hash, appending to lists, 
        union/intersection/difference on sets, and getting sorted-set member with top rank.
	\item {\bf Lua Scripting}
        Lua scripting enable you to run your own code, in an atomic matter inside the server.
        Unlike transactions, you can add non-Redis logic to this atomic operation. We used 
        Lua scripting to speed-up and algorithem which took long time to run. \footnote{Sara: 
        we are kind of abusing this feature, by locking the db and assuming single client, 
        should we mention that?}
\end{itemize}

Here, some of the algorithms were implemented in Python using redis API, and
some were implemented as Lua scripts (to minimize Redis API calls). When an
index was needed, we simply used another Redis DB (you get 16 with the default
configuration). 
The graphs were represented using adjacency lists, i.e. a key is a node-id and
it's value is a set of his neighbors. We also kept a nodes database <id, name>, 
basicall just to get a node count (i.e. needed for the Rooted PageRank implementation),
because redis can't hold empty sets.
\linebreak

Implementation details:
\begin{itemize}
	\item {\bf Helper Database} 
        We only generated one database speed up the Preferential attachment algorithm:
	    topN (id, number of neighbors), a database which holds 101 nodes with most neighbors.
	\item {\bf Common Neighbors (global)} 
        We implemented this algorithm using the Lua scripting feature. First we accumulate 
        the number of common neighbors for each node pair, then iterated over the results 
        to keep the top scoring, and return a sorted result.
	\item {\bf Jaccard's Coefficient (global)}
        Using Lua scripting we used the first part of the Common Neighbors implementation,
        and the relation between the cardinality of union and intersection, and that redis
        can give us the cardinality of a set in a single operation (i.e. number of neighbors)
        we calculated the score and continued similarly to the above implementation.
	\item {\bf Adamic/Adar (global)} 
        Using the Lua scripting, we accumulated list of common neighbors for each pair,
        then went over that list and calculated the algorithm, keeping only the top scoring pairs.
	\item {\bf Preferential attachment (Global)}
        We used the helper database that we created beforehand, to find pairs with maximal product.
	\item {\bf Common Neighbors (for node)}
        We used the same logic as with the global implementation, but with the Python API,
        as it was fast enough.
	\item {\bf Jaccard's Coefficient (for node)}
        We used the same logic as with the global implementation, but with the Python API,
        as it was fast enough.
	\item {\bf Adamic/Adar (for node)}
        We used the same logic as with the global implementation, but with the Python API,
        as it was fast enough.
	\item {\bf Preferential attachment (for node)}
        We used the same logic as with the global implementation.
	\item {\bf Graph Distance (for node)}
        Using the Python API and an iterative loop, we started with the source node 
        as depth 0, on each iteration we expended all the nodes from the previous depth.
	\item {\bf Katz (for node)}
        Using Lua, we started by calculating the $|P^l(x,y)|$ for all reachable nodes in depth 3,
        and then used that to calculate the score.
	\item {\bf Rooted PageRank (for node)}
        Using Lua, we used an iterative loop over a temporary table <id, rpr, new-rpr>, initiated with all the 
        nodes in the graph, and 1/N value where N is the number of nodes in the graph. On every 
        iteration we updated the new-rpr value, using the formula above. We stopped when the algorithm
        converged on the top-10 scoring nodes and their order.
\end{itemize}

\subsection{Neo4J}
Neo4J is a multi-platform, open-source, graph database supported by Neo
Technology. Some of it's main features are:
\begin{itemize}
    \item {\bf transactions}
        Neo4J supports ACID transactions, similar to RDBMS. This also enables 
        you to send chunk of commands to the database instead of single 
        instactions and avoid network latency for each call. We tried to use
        this to load our graph, but this method is just too slow for bulk insertions.
    \item {\bf Embedded mode}
        Embedding Neo4J in your application, mainly saves time on REST calls 
        and enables fast interaction with the database. We used that feature 
        to load the graph, and the move the generated files to the server.
        We found that currently, this is the fastest way to bulk insert a 
        large graph to Neo4J.
    \item {\bf Cypher query language}
        Cypher is a declerative query language for graphs, enabling you to
        match pattern, filter on properties and make changes. It's syntax is
        much like SQL, e.g. friends of friends which are not directly connected:
        \begin{verbatim}
            START n=node(...)
            MATCH n-->m-->o
            WHERE not ( n-->o )
            RETURN o
        \end{verbatim}
    \item {\bf Lucene Indexing}
\end{itemize}
ACID transactions, expressive graph query
language, indexing and high availability. It can operate in an embedded or
client-server architecture. 

In this database, we attempted to use only Neo4j's declarative query language
(Cypher) to implement the algorithms, and the client-server architecture to run
them with. The benchmarking was performed using the Python API, which also
assisted in implementing some multi-query algorithms. We found that the best
way to load the graph into Neo4J was to use the BatchInserter class in the
embedded architecture, and copy the created files into the server. 

There are some limitations to the Cypher language users should be aware of:
\begin{itemize}
\item There are not many built in functions (e.g. no Power, Log, or Rand
  functions) 
\item No support for user defined functions
\item Queries are really slow when matching a non-trivial pattern over the whole
graph (e.g. common neighbors)  
\end{itemize}

\section{Experiments}
We benchmarked the above implementations using 10 undirected graphs:
\begin{itemize}
\item Three graphs were extracted from the DBLP XML records using the authors as
nodes, and co-authorship relation as edges. Each graph was over a different
time period, and  we only kept authors with 3 or more publication within the
selected time period (core-3). 

\item Seven graphs from the Stanford Network Analysis Project (SNAP) dataset
  collection. No changes were made to these graphs.
\end{itemize}

Graphs to add:
\begin{enumerate}
\item Top N index generation (significantly faster on MySQL)
\item Graph Distance (significantly faster on Redis)
\item Jaccard Coefficient (faster on Neo4J)
\end{enumerate}

\section{Conclusions}
The main conclusion we took from this experience is that there is no silver-bullet for storing and running algorithms over social-network graphs. Generally speaking, MySQL seems to have an edge with indices-based implementation, Redis seems to be extremely flexible and open to endless optimization, and Neo4J's Cypher is leading with implementation simplicity.
If we were to build a social network database we'd consider holding replicas in server types of system. While this solution might not be disk-space efficient, it'll provide us the opportunity to achieve the fastest query time with minimal time investment.

Please note that we didn't use any scale out features. A large network implementation can't pick a solution which doesn't have it. \#TODO
