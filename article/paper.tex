\section{Introduction}
The best paper in the world is~\cite{Liben-Nowell:2003:LPP:956863.956972}.

\input link-prediction

\section{Implementation}
The selected algorithms were implemented and tested over three different 
database systems: Relational, Key-Value store and Graph. 
In each system we attempted to implement the algorithms as natively as possible, 
using that system's features and applying common optimizations. 

For the bechmarking we chose MySQL, Redis and Neo4J.
These databases are all open-source, enabling us to publish these benchmarks,
and popular in their domain, therefore considered as a viable option for such social network implementation.

\subsection{MySQL}
MySQL is a popular multi-platform, open-source relational database management
system, sponsored by Oracle. It can be used in client-server or embedded
architecture and it's main features include: 
\begin{itemize}
	\item {\bf Pluggable storage-engines:} MySQL supports several storage engines, 
		most notables are MyISM (fast, simple, no ACID support, no foreign keys) and
		InnoDB (default, supports transactions, ACID and foreign keys).
	\item {\bf Stored Procedures} Like most other relational databases MySQL supports 
		stored procedures execution. Advantages of this feature include 
		avoidance of network traffic for the SQL queries and intermediate results,
		and encapsulation of a multi-query logic in one place.
	\item {\bf Fast Bulk Data Loading} MySQL support very fast data loading from file,
		with it's 'LOAD DATA' statement. From all the systems we tested, this offered 
		the easiest and fastest to load our graph.
\end{itemize}

In this case, the algorithms were implemented as a SQL stored-procedures only,
using indices and intermediate tables when possible. A Python script was used
to run these stored-procedures and collect the benchmarks. For a storage-engine 
we chose InnoDB, the default engine in MySQL 5.5, as it out-performs MyISM in 
most senarios. \footnote{Sara: can we cite Oracle white papers? 
http://www.oracle.com/partners/en/knowledge-zone/mysql-5-5-innodb-myisam-522945.pdf}
\linebreak
Implementation details:
\begin{itemize}
	\item {\bf Helper Tables} 
        We generated the following helper tables to speed up some algorithms:
		\begin{itemize}
			\item {common-neighbors (id1, id2, neighbor)}
			\item {common-neighbors-count (id1, id2, number of common neighbors)}
			\item {neighbors (id, number of neighbors)}
			\item {topN (id, number of neighbors)}
				This table is simply the top 101 items of the neighbors table.
		\end{itemize}
	\item {\bf Common Neighbors (global)} 
		To find the top N records with most common neighbors, 
		we selected them from the common-neighbors-count table.
	\item {\bf Jaccard's Coefficient (global)} 
		We used the following relation between the cardinality of union and intersection:
		\[{|N(x) \cup N(y)|} = {|N(x)| + |N(y)| - |N(x) \cap N(y)|}\]
		So to calculate the score we used the common-neighbors-count and the neighbors helper tables.
	\item {\bf Adamic/Adar (global)} 
		We used the common-neighbors joined with the neighbors helper table.
	\item {\bf Preferential attachment (Global)}
		We used only the topN helper table, because the highest products 
		must be combinations of the nodes with most neighbors.
	\item {\bf Common Neighbors (for node)}
		We used a simple join on the edges table, no helper tables required.
	\item {\bf Jaccard's Coefficient (for node)}
		We used the relation between the cardinality of union and intersection,
		with join of two edges tables, and two neighbors helper tables.
	\item {\bf Adamic/Adar (for node)}
		We used join on the edges table, with the neighbors helper table.
	\item {\bf Preferential attachment (for node)}
		We used the topN helper table, just like in the global version.
	\item {\bf Graph Distance (for node)}
		We used a recursive procedure, starting with a temporary table with all the node's neighbors,
		and on each iteration N we added all the neighbors of nodes in depth N-1. This implementation
		required us to reconfigure MySQL maximum recursion depth.
	\item {\bf Katz (for node)}
		We used a recursive procedure to calculate $|P^l(x,y)|$ for all reachable nodes in depth 3,
		and stored that in a temporary table. We then used that to calculate the score.
	\item {\bf Rooted PageRank (for node)}
        We used an iterative loop over a temporary table <id, rpr, new-rpr>, initiated with all the 
        nodes in the graph, and 1/N value where N is the number of nodes in the graph. On every 
        iteration we updated the new-rpr value, using the formula above. We stopped when the algorithm
        converged on the top-10 scoring nodes and their order.
\end{itemize}

\subsection{Redis}
Redis is an open-source, in-memory key-value store database system, sponsored
by VMware. It's written in C and has atomic operations, we used the following features:
\begin{itemize}
	\item {\bf Transactions}
        You can use redis transaction to save time spent on network trafic 
        between the client API and the server. We used that feature to speed up
        the graph load significantly.
	\item {\bf Data structure as value}
        Redis support storing many types of data structures as valuse and 
        performe efficient, atomic operation over them. I.e. there are strings,
        hashes (key-value pairs), lists, sets (in which we used to store the 
        adjacency lists), and sorted-sets (like sets, but with rank for each item).
        Operations include: incrementing value in hash, appending to lists, 
        union/intersection/difference on sets, and getting sorted-set member with top rank.
	\item {\bf Lua Scripting}
        Lua scripting enable you to run your own code, in an atomic matter inside the server.
        Unlike transactions, you can add non-Redis logic to this atomic operation. We used 
        Lua scripting to speed-up and algorithem which took long time to run.\footnote{Sara: we are kind of abusing this feature, by locking the db and assuming single client, should we mention that?}
\end{itemize}

Here, some of the algorithms were implemented in Python using redis API, and
some were implemented as Lua scripts (to minimize Redis API calls). When an
index was needed, we simply used another Redis DB (you get 16 with the default
configuration). 
The graphs were represented using adjacency lists, i.e. a key is a node-id and
it's value is a set of his neighbors. That implementation posed a limitation,
since we couldn't store nodes without neighbors, as redis doesn't allow to
store empty sets. This isn't such an issue for us, as all the algorithems we tested
return an empty set for such nodes, and we still kept a nodes db <id, name> which
could provide us with the node count (i.e. needed for the Rooted PageRank implementation)
\linebreak
Implementation details:
\begin{itemize}
	\item {\bf Helper Database} 
        We only generated one database speed up the Preferential attachment algorithm:
	    topN (id, number of neighbors), a database which holds 101 nodes with most neighbors.
	\item {\bf Common Neighbors (global)} 
        We implemented this algorithm using the Lua scripting feature. TODO
	\item {\bf Jaccard's Coefficient (global)} 
	\item {\bf Adamic/Adar (global)} 
	\item {\bf Preferential attachment (Global)}
	\item {\bf Common Neighbors (for node)}
	\item {\bf Jaccard's Coefficient (for node)}
	\item {\bf Adamic/Adar (for node)}
	\item {\bf Preferential attachment (for node)}
	\item {\bf Graph Distance (for node)}
	\item {\bf Katz (for node)}
	\item {\bf Rooted PageRank (for node)}
\end{itemize}

\subsection{Neo4J}
Neo4J is a multi-platform, open-source, graph database supported by Neo
Technology. It features full ACID transactions, expressive graph query
language, indexing and high availability. It can operate in an embedded or
client-server architecture. 

In this database, we attempted to use only Neo4j's declarative query language
(Cypher) to implement the algorithms, and the client-server architecture to run
them with. The benchmarking was performed using the Python API, which also
assisted in implementing some multi-query algorithms. We found that the best
way to load the graph into Neo4J was to use the BatchInserter class in the
embedded architecture, and copy the created files into the server. 

There are some limitations to the Cypher language users should be aware of:
\begin{itemize}
\item There are not many built in functions (e.g. no Power, Log, or Rand
  functions) 
\item No support for user defined functions
\item Queries are really slow when matching a non-trivial pattern over the whole
graph (e.g. common neighbors)  
\end{itemize}

\section{Experiments}
We benchmarked the above implementations using 10 undirected graphs:
\begin{itemize}
\item Three graphs were extracted from the DBLP XML records using the authors as
nodes, and co-authorship relation as edges. Each graph was over a different
time period, and  we only kept authors with 3 or more publication within the
selected time period (core-3). 

\item Seven graphs from the Stanford Network Analysis Project (SNAP) dataset
  collection. No changes were made to these graphs.
\end{itemize}

Graphs to add:
\begin{enumerate}
\item Top N index generation (significantly faster on MySQL)
\item Graph Distance (significantly faster on Redis)
\item Jaccard Coefficient (faster on Neo4J)
\end{enumerate}

\section{Conclusions}
The main conclusion we took from this experience is that there is no silver-bullet for storing and running algorithms over social-network graphs. Generally speaking, MySQL seems to have an edge with indices-based implementation, Redis seems to be extremely flexible and open to endless optimization, and Neo4J's Cypher is leading with implementation simplicity.
If we were to build a social network database we'd consider holding replicas in server types of system. While this solution might not be disk-space efficient, it'll provide us the opportunity to achieve the fastest query time with minimal time investment.

Please note that we didn't use any scale out features. A large network implementation can't pick a solution which doesn't have it. \#TODO
